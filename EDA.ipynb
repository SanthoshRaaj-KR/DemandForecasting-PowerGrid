{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a426d6f-105c-4425-8532-615405b1a633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c750c65-6963-44dc-a776-d8c664a9aa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('India_Elec_data_(Jan2020-Mar2025).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "987328be-27cd-4255-b17e-c1ff974bb477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Max Demand Met</th>\n",
       "      <th>Shortage During Peak</th>\n",
       "      <th>Energy Met</th>\n",
       "      <th>Drawl Schedule</th>\n",
       "      <th>OD(+) / UD(-)</th>\n",
       "      <th>Max OD</th>\n",
       "      <th>Energy Shortage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62972.000000</td>\n",
       "      <td>64006.000000</td>\n",
       "      <td>64014.000000</td>\n",
       "      <td>64024.000000</td>\n",
       "      <td>64024.000000</td>\n",
       "      <td>64020.000000</td>\n",
       "      <td>64024.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5914.468621</td>\n",
       "      <td>31.847999</td>\n",
       "      <td>118.034654</td>\n",
       "      <td>53.667034</td>\n",
       "      <td>0.047723</td>\n",
       "      <td>283.421821</td>\n",
       "      <td>1.251784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6572.822893</td>\n",
       "      <td>175.700777</td>\n",
       "      <td>135.339533</td>\n",
       "      <td>63.055726</td>\n",
       "      <td>6.855528</td>\n",
       "      <td>301.096262</td>\n",
       "      <td>9.975461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>-75.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1415.000000</td>\n",
       "      <td>-908.000000</td>\n",
       "      <td>-1065.000000</td>\n",
       "      <td>-43.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>358.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3452.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.100000</td>\n",
       "      <td>30.200000</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9666.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>194.400000</td>\n",
       "      <td>86.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30675.000000</td>\n",
       "      <td>3311.000000</td>\n",
       "      <td>685.000000</td>\n",
       "      <td>1502.000000</td>\n",
       "      <td>66.300000</td>\n",
       "      <td>15623.000000</td>\n",
       "      <td>1153.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Max Demand Met  Shortage During Peak    Energy Met  Drawl Schedule  \\\n",
       "count    62972.000000          64006.000000  64014.000000    64024.000000   \n",
       "mean      5914.468621             31.847999    118.034654       53.667034   \n",
       "std       6572.822893            175.700777    135.339533       63.055726   \n",
       "min         36.000000            -75.000000      0.000000    -1415.000000   \n",
       "25%        358.000000              0.000000      6.600000        4.700000   \n",
       "50%       3452.000000              0.000000     69.100000       30.200000   \n",
       "75%       9666.250000              0.000000    194.400000       86.300000   \n",
       "max      30675.000000           3311.000000    685.000000     1502.000000   \n",
       "\n",
       "       OD(+) / UD(-)        Max OD  Energy Shortage  \n",
       "count   64024.000000  64020.000000     64024.000000  \n",
       "mean        0.047723    283.421821         1.251784  \n",
       "std         6.855528    301.096262         9.975461  \n",
       "min      -908.000000  -1065.000000       -43.800000  \n",
       "25%        -0.800000     45.000000         0.000000  \n",
       "50%        -0.100000    200.000000         0.000000  \n",
       "75%         0.300000    438.000000         0.000000  \n",
       "max        66.300000  15623.000000      1153.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09bbd0f3-4a6e-4b40-a0ff-dd92a597b1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Date\"] = pd.to_datetime(data[\"Date\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cba2af7-ea41-4e3d-a324-d0983b0ab9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATE = \"Andhra Pradesh\"\n",
    "df = data[data[\"State\"] == STATE].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb001c8-9869-4de1-aefb-aefd97c32b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=[\"Drawl Schedule\", \"OD(+) / UD(-)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88753990-1ba6-425b-9b62-92655b71e164",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Actual_Drawl\"] = df[\"Drawl Schedule\"] + df[\"OD(+) / UD(-)\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d327536a-b9a1-420b-b670-5ce9b8625227",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(\"Date\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d608dcd5-14f1-403e-b709-95a90e8c97a6",
   "metadata": {},
   "source": [
    "**Correlation between drawl and actual drawn**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eea8ea4-d398-4bf1-9b1e-893d9db18b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation (S_t, A_t): 0.9972094125053577\n"
     ]
    }
   ],
   "source": [
    "corr = df[\"Drawl Schedule\"].corr(df[\"Actual_Drawl\"])\n",
    "print(\"Correlation (S_t, A_t):\", corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7b5c4a-177b-4a32-b1f4-6fa461cbda1c",
   "metadata": {},
   "source": [
    "Error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b76adb0a-07ef-4d4b-8d8d-f2fc56afcb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_error': np.float64(0.037566702241195356), 'std_error': 1.627138258741535, 'max_overdraw': 21.799999999999997, 'max_underdraw': -8.0}\n"
     ]
    }
   ],
   "source": [
    "df[\"Error\"] = df[\"Actual_Drawl\"] - df[\"Drawl Schedule\"]\n",
    "\n",
    "error_stats = {\n",
    "    \"mean_error\": df[\"Error\"].mean(),\n",
    "    \"std_error\": df[\"Error\"].std(),\n",
    "    \"max_overdraw\": df[\"Error\"].max(),\n",
    "    \"max_underdraw\": df[\"Error\"].min()\n",
    "}\n",
    "\n",
    "print(error_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263abf17-2a7a-4707-9352-601cf948803b",
   "metadata": {},
   "source": [
    "**Relational Error , Error / Predicted Drawl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb2e60b2-f9bf-41fc-9557-2fda73e4ff29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_rel_od': np.float64(-inf), 'std_rel_od': nan, 'max_rel_od': 5.0, 'min_rel_od': np.float64(-inf)}\n"
     ]
    }
   ],
   "source": [
    "df[\"Rel_OD\"] = df[\"Error\"] / df[\"Drawl Schedule\"]\n",
    "\n",
    "rel_stats = {\n",
    "    \"mean_rel_od\": df[\"Rel_OD\"].mean(),\n",
    "    \"std_rel_od\": df[\"Rel_OD\"].std(),\n",
    "    \"max_rel_od\": df[\"Rel_OD\"].max(),\n",
    "    \"min_rel_od\": df[\"Rel_OD\"].min()\n",
    "}\n",
    "\n",
    "print(rel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7b74e1-6d5f-496d-88d8-4381bfc32c92",
   "metadata": {},
   "source": [
    "**Rolling OD -  Mistakes do they stay or move on**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b218db6-f3ad-4cfa-bd54-bf017681a281",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW = 100  # days\n",
    "\n",
    "df[\"OD_roll_mean\"] = df[\"Error\"].rolling(WINDOW).mean()\n",
    "df[\"OD_roll_std\"]  = df[\"Error\"].rolling(WINDOW).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d805b2ae-2842-4f9e-93e2-6c56c5c1ed06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corr(OD_t-1, A_t): 0.2764334845350078\n",
      "Corr(OD_t-2, A_t): 0.2336037361346498\n",
      "Corr(OD_t-3, A_t): 0.19137349506160423\n",
      "Corr(OD_t-7, A_t): 0.11861216228691987\n"
     ]
    }
   ],
   "source": [
    "for lag in [1, 2, 3, 7]:\n",
    "    df[f\"OD_lag_{lag}\"] = df[\"Error\"].shift(lag)\n",
    "    corr_lag = df[f\"OD_lag_{lag}\"].corr(df[\"Actual_Drawl\"])\n",
    "    print(f\"Corr(OD_t-{lag}, A_t): {corr_lag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f6013dd-38b9-4981-9c7b-5a8411f397c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 1.0156041826865632\n",
      "Intercept: -1.0706266980158006\n",
      "R^2: 0.9944266123892803\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = df[[\"Drawl Schedule\"]]\n",
    "y = df[\"Actual_Drawl\"]\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Slope:\", model.coef_[0])\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "print(\"R^2:\", model.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36490190-5384-4d2f-ab1e-387d3120c0fe",
   "metadata": {},
   "source": [
    "**A Summation of this but for all the states and considering the mean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8711deef-7dc9-429c-b6a4-b234da6473ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"India_Elec_data_(Jan2020-Mar2025).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ff9a935-6cd7-4718-91f7-0fa6601067d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "\n",
    "# Drop rows needed for drawl logic\n",
    "df = df.dropna(subset=[\"Drawl Schedule\", \"OD(+) / UD(-)\"])\n",
    "\n",
    "# Actual Drawl\n",
    "df[\"Actual_Drawl\"] = df[\"Drawl Schedule\"] + df[\"OD(+) / UD(-)\"]\n",
    "\n",
    "# Error (OD)\n",
    "df[\"Error\"] = df[\"Actual_Drawl\"] - df[\"Drawl Schedule\"]\n",
    "\n",
    "# Relative OD \n",
    "df[\"Rel_OD\"] = np.where(\n",
    "    df[\"Drawl Schedule\"] != 0,\n",
    "    df[\"Error\"] / df[\"Drawl Schedule\"],\n",
    "    np.nan\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "353a5742-e22c-4a64-88a0-16c04ad60158",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_summary = (\n",
    "    df.groupby(\"State\")\n",
    "      .agg(\n",
    "          mean_scheduled_drawl=(\"Drawl Schedule\", \"mean\"),\n",
    "          mean_actual_drawl=(\"Actual_Drawl\", \"mean\"),\n",
    "          mean_error=(\"Error\", \"mean\"),\n",
    "          std_error=(\"Error\", \"std\"),\n",
    "          mean_rel_od=(\"Rel_OD\", \"mean\"),\n",
    "          std_rel_od=(\"Rel_OD\", \"std\"),\n",
    "          observations=(\"Error\", \"count\")\n",
    "      )\n",
    "      .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d53d9a-b36c-46cb-8293-3ab6fe0b7e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   State  mean_scheduled_drawl  mean_actual_drawl  mean_error  \\\n",
      "0                     HP             15.128368          14.963895   -0.164474   \n",
      "1              Telangana             96.218220          96.202754   -0.015466   \n",
      "2                 Punjab             95.984958          94.842055   -1.142903   \n",
      "3                  NR UP            151.738030         151.068273   -0.669756   \n",
      "4                     MP            143.355427         141.176291   -2.179136   \n",
      "5            West Bengal             40.578549          39.756777   -0.821772   \n",
      "6                     DD              2.462153          -0.106597   -2.568750   \n",
      "7           SR Karnataka             72.663289          72.278462   -0.384828   \n",
      "8                  Delhi             79.746928          78.663347   -1.083581   \n",
      "9                 Kerala             54.513983          54.905350    0.391367   \n",
      "10               Haryana            114.984799         114.604131   -0.380667   \n",
      "11               Gujarat            158.815519         158.458422   -0.357097   \n",
      "12          Chhattisgarh             47.128034          46.632273   -0.495760   \n",
      "13             ER Odisha             34.218549          33.390365   -0.828184   \n",
      "14        Andhra Pradesh             71.018997          71.056564    0.037567   \n",
      "15            Tamil Nadu            173.226734         172.072839   -1.153895   \n",
      "16                 Bihar             97.019386          96.649788   -0.369597   \n",
      "17        WR Maharashtra            173.781326         172.256077   -1.525249   \n",
      "18                 Assam             24.949311          25.216790    0.267479   \n",
      "19             Rajasthan             84.713612          83.715254   -0.998358   \n",
      "20           Essar steel              5.344554           5.289109   -0.055446   \n",
      "21           Uttarakhand             23.923835          24.227542    0.303708   \n",
      "22                   DVC            -39.883157         -39.941314   -0.058157   \n",
      "23         NER Meghalaya              3.185064           3.125000   -0.060064   \n",
      "24  J&K(UT) & Ladakh(UT)             38.332552          38.299777   -0.032775   \n",
      "25            Chandigarh              4.800000           4.695551   -0.104449   \n",
      "26            Puducherry              8.571491           8.292790   -0.278701   \n",
      "27               Tripura              4.098358           4.042002   -0.056356   \n",
      "28                   DNH             23.328655          38.967161   15.638506   \n",
      "29             Jharkhand             21.010972          19.856913   -1.154059   \n",
      "30                   Goa             11.834640          12.084057    0.249417   \n",
      "31               Mizoram              1.428284           1.294756   -0.133528   \n",
      "32              Nagaland              2.270498           2.219915   -0.050583   \n",
      "33               Manipur              2.811917           2.760646   -0.051271   \n",
      "34     Arunachal Pradesh              2.395945           2.305496   -0.090448   \n",
      "35                Sikkim              1.505932           1.472511   -0.033422   \n",
      "\n",
      "    std_error  mean_rel_od  std_rel_od  observations  corr_S_A  \n",
      "0    1.000430    -0.002616    1.552107          1900  0.999694  \n",
      "1    1.316865    -0.003120    0.085618          1888  0.999458  \n",
      "2    1.860009    -0.013812    0.019258          1888  0.999348  \n",
      "3    2.279063    -0.005811    0.018013          1888  0.999333  \n",
      "4    2.642954    -0.014907    0.021549          1898  0.998846  \n",
      "5    1.622386    -0.034444    0.619337          1874  0.998525  \n",
      "6   47.667271     0.037495    0.054384           864  0.998454  \n",
      "7    1.974536    -0.033917    0.891968          1885  0.998441  \n",
      "8    1.479754    -0.014166    0.020776          1888  0.998264  \n",
      "9    0.908853     0.005095    0.020815          1888  0.998226  \n",
      "10   2.299172    -0.002980    0.030330          1888  0.998131  \n",
      "11   3.662337     0.001008    0.028733          1888  0.997419  \n",
      "12   1.195734    -0.013101    0.032917          1887  0.997332  \n",
      "13   1.298342    -0.018477    0.376014          1806  0.997270  \n",
      "14   1.627138    -0.000047    0.125284          1874  0.997209  \n",
      "15   2.900010    -0.008013    0.021773          1874  0.997200  \n",
      "16   1.840056    -0.003869    0.019179          1888  0.996698  \n",
      "17   2.789897    -0.009372    0.016816          1810  0.996033  \n",
      "18   0.659970     0.009635    0.026409          1888  0.995387  \n",
      "19   2.748659    -0.017156    0.052685          1888  0.994814  \n",
      "20   0.324184     0.036261    0.153520           101  0.994382  \n",
      "21   0.749433     0.012623    0.046733          1888  0.993672  \n",
      "22   1.013757    -0.000965    0.037725          1888  0.993409  \n",
      "23   0.243309    -0.023569    0.397616          1888  0.993094  \n",
      "24   1.907985     0.002164    0.061397          1791  0.989483  \n",
      "25   0.300646    -0.023088    0.064721          1888  0.978691  \n",
      "26   0.247527    -0.033705    0.032600          1817  0.977576  \n",
      "27   0.372095    -0.029019    0.113766          1888  0.974636  \n",
      "28  14.328043     0.548662    0.503392          1888  0.949133  \n",
      "29   1.067040    -0.055327    0.051594          1121  0.936111  \n",
      "30   0.964016     0.021474    0.083609          1888  0.899030  \n",
      "31   0.218837    -0.093878    0.218337          1888  0.834739  \n",
      "32   0.168505    -0.019485    0.077107          1888  0.794006  \n",
      "33   0.251816    -0.015071    0.086596          1888  0.785721  \n",
      "34   0.279194    -0.025906    0.132203          1874  0.764927  \n",
      "35   0.264406     0.029451    0.664100          1888  0.683378  \n"
     ]
    }
   ],
   "source": [
    "corr_list = []\n",
    "\n",
    "for state, sdf in df.groupby(\"State\"):\n",
    "    if len(sdf) > 30:\n",
    "        corr = sdf[\"Drawl Schedule\"].corr(sdf[\"Actual_Drawl\"])\n",
    "        corr_list.append({\"State\": state, \"corr_S_A\": corr})\n",
    "\n",
    "corr_df = pd.DataFrame(corr_list)\n",
    "\n",
    "# Merge correlation into summary\n",
    "state_summary = state_summary.merge(corr_df, on=\"State\", how=\"left\")\n",
    "\n",
    "# Sort by predictability\n",
    "state_summary = state_summary.sort_values(\n",
    "    by=\"corr_S_A\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(state_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f0564c5-c370-4815-bba2-8d5d013c062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Master_Weather_Electricity_Data_FIXED.csv for Feature Selection...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load the Master Database\n",
    "# Use the file you just generated (either _FIXED or the normal one)\n",
    "file_path = 'Master_Weather_Electricity_Data_FIXED.csv' \n",
    "print(f\"Loading {file_path} for Feature Selection...\")\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b607263c-8b79-455b-9415-79a3469d8af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 12 weather variables: ['om_temp_mean', 'om_temp_max', 'om_dewpoint', 'om_humidity', 'om_wind_speed', 'om_wind_gusts', 'om_precip', 'om_solar', 'nasa_temp_max', 'nasa_humidity', 'nasa_solar', 'nasa_precip']\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare Data\n",
    "# Ensure we have the target 'Gap' (Actual - Schedule)\n",
    "# We fill NaNs with 0 to ensure correlations don't break, though dropping is often better\n",
    "df['Drawl_Schedule'] = pd.to_numeric(df['Drawl_Schedule'], errors='coerce').fillna(0)\n",
    "df['Actual_Drawl'] = pd.to_numeric(df['Actual_Drawl'], errors='coerce').fillna(0)\n",
    "df['Gap'] = df['Actual_Drawl'] - df['Drawl_Schedule']\n",
    "\n",
    "# Identify all Weather Columns (Open-Meteo & NASA)\n",
    "weather_cols = [c for c in df.columns if c.startswith('om_') or c.startswith('nasa_')]\n",
    "print(f\"Analyzing {len(weather_cols)} weather variables: {weather_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29ae07fb-a258-43ff-94a5-a91be57c2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. CALCULATE CORRELATIONS\n",
    "results = {}\n",
    "\n",
    "for state in df['State'].unique():\n",
    "    state_data = df[df['State'] == state]\n",
    "    \n",
    "    # We need enough data points to run a correlation\n",
    "    if len(state_data) > 50:\n",
    "        # Calculate correlation of all weather cols against 'Gap'\n",
    "        # We use .corrwith() to do it in one shot against the target series\n",
    "        corrs = state_data[weather_cols].corrwith(state_data['Gap'])\n",
    "        results[state] = corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1c3acf2-8cf2-4d90-933d-c35611b28487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. CONVERT TO DATAFRAME\n",
    "corr_df = pd.DataFrame(results).T # Transpose so States are rows, Weather Vars are columns\n",
    "\n",
    "# 5. CALCULATE AGGREGATE SCORES (The \"Significance\")\n",
    "# We take the ABSOLUTE mean because a strong negative correlation (-0.8) is just as important as positive\n",
    "avg_scores = corr_df.abs().mean()\n",
    "\n",
    "# Add the 'AVERAGE_SCORE' row to the bottom of the dataframe\n",
    "corr_df.loc['AVERAGE_IMPORTANCE'] = avg_scores\n",
    "\n",
    "# Sort columns by their Global Importance (High to Low)\n",
    "sorted_cols = avg_scores.sort_values(ascending=False).index\n",
    "corr_df = corr_df[sorted_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2591086-81ae-465c-9dac-a5834e9fee6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DETAILED WEATHER IMPACT SCORES (Correlation with Demand Gap)\n",
      "================================================================================\n",
      "                      om_temp_mean  nasa_solar  om_temp_max  om_precip  om_solar  nasa_precip  nasa_temp_max  om_dewpoint  om_humidity  om_wind_gusts  om_wind_speed  nasa_humidity\n",
      "Andhra Pradesh               0.140       0.177        0.134     -0.150     0.199       -0.086          0.088        0.027       -0.104         -0.067         -0.140         -0.071\n",
      "Arunachal Pradesh            0.058       0.105        0.073     -0.143     0.119       -0.053          0.050        0.017       -0.084         -0.010         -0.025         -0.061\n",
      "Assam                        0.142       0.106        0.129     -0.046     0.103       -0.094          0.107        0.144        0.057         -0.089         -0.140          0.019\n",
      "Bihar                        0.043       0.118        0.070     -0.087     0.140       -0.071          0.061       -0.046       -0.114         -0.027         -0.057         -0.098\n",
      "Chandigarh                  -0.034       0.041       -0.019     -0.197     0.065       -0.207         -0.003       -0.082       -0.041         -0.060         -0.072         -0.101\n",
      "Chhattisgarh                -0.053       0.096       -0.012     -0.183     0.112       -0.181         -0.040       -0.136       -0.106         -0.155         -0.124         -0.064\n",
      "DD                          -0.040      -0.013       -0.053     -0.004    -0.023       -0.012         -0.044        0.033        0.051         -0.047         -0.028          0.039\n",
      "DNH                          0.017      -0.098       -0.007      0.020    -0.007        0.031         -0.032       -0.008       -0.024         -0.090          0.003         -0.002\n",
      "DVC                          0.160       0.089        0.140      0.019     0.062        0.029          0.142        0.149        0.058          0.077          0.091         -0.001\n",
      "Delhi                       -0.187      -0.135       -0.181     -0.052    -0.126       -0.098         -0.179       -0.113        0.073         -0.133         -0.072          0.006\n",
      "ER Odisha                    0.174       0.206        0.173     -0.084     0.168       -0.084          0.161        0.146        0.018          0.059          0.078         -0.054\n",
      "Essar steel                  0.099         NaN        0.079      0.012     0.028          NaN            NaN        0.080        0.046          0.010          0.004            NaN\n",
      "Goa                          0.129       0.046        0.037     -0.021     0.045       -0.010          0.077        0.126        0.055         -0.015         -0.042          0.045\n",
      "Gujarat                     -0.046       0.085        0.013     -0.097     0.051       -0.081          0.024       -0.076       -0.074         -0.116         -0.088         -0.087\n",
      "HP                          -0.045       0.072       -0.031     -0.083     0.090       -0.035          0.006       -0.114       -0.145          0.018          0.097         -0.130\n",
      "Haryana                     -0.046       0.057       -0.043     -0.130     0.054       -0.147         -0.048       -0.019        0.027         -0.123         -0.070         -0.007\n",
      "J&K(UT) & Ladakh(UT)         0.126       0.135        0.162     -0.214     0.104       -0.176          0.156        0.027       -0.256         -0.019         -0.045         -0.216\n",
      "Jharkhand                    0.055       0.119        0.101     -0.143     0.158       -0.159          0.089       -0.114       -0.167         -0.080         -0.073         -0.149\n",
      "Kerala                       0.298       0.085        0.261     -0.063     0.101       -0.102          0.226        0.042       -0.140         -0.120         -0.154         -0.155\n",
      "MP                           0.071       0.030        0.028      0.050     0.002        0.022          0.022        0.113        0.079         -0.027         -0.023          0.088\n",
      "Manipur                      0.193       0.112        0.190     -0.064     0.135       -0.018          0.186        0.132       -0.014          0.135          0.088          0.010\n",
      "Mizoram                        NaN       0.103          NaN        NaN       NaN       -0.041          0.076          NaN          NaN            NaN            NaN          0.051\n",
      "NER Meghalaya                  NaN       0.104          NaN        NaN       NaN       -0.155         -0.085          NaN          NaN            NaN            NaN         -0.117\n",
      "NR UP                        0.066       0.116        0.069     -0.084     0.115       -0.083          0.045        0.081        0.019         -0.082         -0.081          0.040\n",
      "Nagaland                    -0.318       0.003       -0.292     -0.216     0.027       -0.164         -0.264       -0.320       -0.192          0.103          0.149         -0.193\n",
      "Puducherry                   0.119       0.114        0.116     -0.114     0.102       -0.126          0.065        0.023       -0.109         -0.003         -0.021         -0.017\n",
      "Punjab                      -0.139       0.063       -0.093     -0.190     0.022       -0.252         -0.092       -0.192       -0.067         -0.128         -0.073         -0.123\n",
      "Rajasthan                    0.073       0.144        0.093     -0.182     0.097       -0.204          0.101       -0.027       -0.108         -0.147         -0.084         -0.087\n",
      "SR Karnataka                 0.135       0.153        0.157     -0.075     0.179       -0.022          0.122       -0.112       -0.158         -0.160         -0.167         -0.117\n",
      "Sikkim                      -0.050      -0.044       -0.045     -0.078    -0.043       -0.054         -0.020       -0.037       -0.002          0.015          0.056         -0.011\n",
      "Tamil Nadu                  -0.117       0.136       -0.117     -0.103     0.136       -0.112         -0.056       -0.020        0.101         -0.094         -0.098          0.018\n",
      "Telangana                    0.074       0.109        0.071     -0.038     0.101       -0.068          0.078        0.030       -0.027          0.035          0.060         -0.052\n",
      "Tripura                      0.307       0.229        0.337     -0.058     0.275       -0.062          0.296        0.218       -0.078          0.044          0.006         -0.031\n",
      "Uttarakhand                 -0.006       0.072       -0.004     -0.110     0.036       -0.097         -0.003        0.014        0.036         -0.179         -0.073         -0.002\n",
      "WR Maharashtra               0.016       0.181        0.082     -0.174     0.193       -0.175          0.126       -0.066       -0.090         -0.113         -0.131         -0.142\n",
      "West Bengal                  0.121       0.151        0.055      0.004     0.051        0.002         -0.007        0.171        0.145          0.036          0.094          0.212\n",
      "AVERAGE_IMPORTANCE           0.109       0.104        0.102      0.097     0.096        0.095          0.091        0.090        0.084          0.077          0.077          0.075\n",
      "\n",
      "================================================================================\n",
      "FINAL VERDICT: VARIABLE SIGNIFICANCE RANKING\n",
      "================================================================================\n",
      "om_temp_mean     0.1087\n",
      "nasa_solar       0.1042\n",
      "om_temp_max      0.1020\n",
      "om_precip        0.0967\n",
      "om_solar         0.0961\n",
      "nasa_precip      0.0946\n",
      "nasa_temp_max    0.0907\n",
      "om_dewpoint      0.0899\n",
      "om_humidity      0.0842\n",
      "om_wind_gusts    0.0769\n",
      "om_wind_speed    0.0766\n",
      "nasa_humidity    0.0748\n",
      "dtype: float64\n",
      "\n",
      "================================================================================\n",
      "RECOMMENDATION\n",
      "================================================================================\n",
      "KEEP these columns (Significant Impact): ['om_temp_mean', 'om_temp_max', 'om_dewpoint', 'om_humidity', 'om_wind_speed', 'om_wind_gusts', 'om_precip', 'om_solar', 'nasa_temp_max', 'nasa_humidity', 'nasa_solar', 'nasa_precip']\n",
      "DROP these columns (Minimal/No Impact): []\n"
     ]
    }
   ],
   "source": [
    "# 6. PRINT RESULTS\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DETAILED WEATHER IMPACT SCORES (Correlation with Demand Gap)\")\n",
    "print(\"=\"*80)\n",
    "# Print the full table (States x Variables)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "print(corr_df.round(3))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL VERDICT: VARIABLE SIGNIFICANCE RANKING\")\n",
    "print(\"=\"*80)\n",
    "print(avg_scores.sort_values(ascending=False).round(4))\n",
    "\n",
    "# 7. RECOMMENDATION: WHICH TO DROP?\n",
    "# Define a threshold (e.g., 0.05). If average impact is lower, it's noise.\n",
    "threshold = 0.05\n",
    "drop_cols = avg_scores[avg_scores < threshold].index.tolist()\n",
    "keep_cols = avg_scores[avg_scores >= threshold].index.tolist()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"KEEP these columns (Significant Impact): {keep_cols}\")\n",
    "print(f\"DROP these columns (Minimal/No Impact): {drop_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5601d19e-b67f-47eb-84cc-09e1a5e310c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "DATA CLEANING COMPLETE\n",
      "---------------------------------------------------\n",
      "Original Columns: 23\n",
      "Final Columns:    10\n",
      "Saved as: 'Final_Model_Data.csv'\n",
      "You are now ready to run the prediction model.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the fixed master file\n",
    "file_path = 'Master_Weather_Electricity_Data_FIXED.csv' \n",
    "# (Or 'Master_Weather_Electricity_Data.csv' if you didn't need the patch)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# 2. Select ONLY the Champions (The variables with the highest scores)\n",
    "# We also keep the core columns: Date, State, Drawl info\n",
    "columns_to_keep = [\n",
    "    'Date', \n",
    "    'State', \n",
    "    'Actual_Drawl', \n",
    "    'Drawl_Schedule', \n",
    "    'Gap',            # The target we are analyzing\n",
    "    'om_temp_mean',   # The Best Temp Metric\n",
    "    'nasa_solar',     # The Best Solar Metric\n",
    "    'om_precip',      # The Best Rain Metric\n",
    "    'om_dewpoint',    # The Best Humidity Metric (Dewpoint combines heat + humidity)\n",
    "    'om_wind_gusts'   # The Best Wind Metric\n",
    "]\n",
    "\n",
    "# 3. Create the Final Model-Ready Dataset\n",
    "final_df = df[columns_to_keep].copy()\n",
    "\n",
    "# 4. Save it\n",
    "final_df.to_csv('Final_Model_Data.csv', index=False)\n",
    "\n",
    "print(\"---------------------------------------------------\")\n",
    "print(\"DATA CLEANING COMPLETE\")\n",
    "print(\"---------------------------------------------------\")\n",
    "print(f\"Original Columns: {len(df.columns)}\")\n",
    "print(f\"Final Columns:    {len(final_df.columns)}\")\n",
    "print(\"Saved as: 'Final_Model_Data.csv'\")\n",
    "print(\"You are now ready to run the prediction model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "417f8a7f-6789-4758-89db-fc3113e93c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Shape: (69012, 10) (Rows, Cols)\n",
      "\n",
      "--- NULL REPORT (Missing Values %) ---\n",
      "               Missing_Rows  Percent_Missing\n",
      "om_temp_mean           3834         5.555556\n",
      "om_precip              3834         5.555556\n",
      "om_dewpoint            3834         5.555556\n",
      "om_wind_gusts          3834         5.555556\n",
      "nasa_solar             1917         2.777778\n",
      "\n",
      "[ACTION] No columns exceeded the 30% missing threshold.\n",
      "\n",
      "[ACTION] Dropped 5751 rows containing NaNs.\n",
      "\n",
      "Final Clean Shape: (63261, 10)\n",
      "Saved as: 'Final_Cleaned_Dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Data\n",
    "file_path = 'Final_Model_Data.csv' \n",
    "# (Or 'Master_Weather_Electricity_Data.csv' if you haven't filtered features yet)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(f\"Original Shape: {df.shape} (Rows, Cols)\")\n",
    "\n",
    "# ==================================================\n",
    "# PART A: THE NULL REPORT\n",
    "# ==================================================\n",
    "print(\"\\n--- NULL REPORT (Missing Values %) ---\")\n",
    "null_counts = df.isnull().sum()\n",
    "null_percent = (df.isnull().sum() / len(df)) * 100\n",
    "\n",
    "# Create a readable table\n",
    "null_df = pd.DataFrame({'Missing_Rows': null_counts, 'Percent_Missing': null_percent})\n",
    "print(null_df[null_df['Missing_Rows'] > 0].sort_values('Percent_Missing', ascending=False))\n",
    "\n",
    "# ==================================================\n",
    "# PART B: THE CLEAN UP STRATEGY\n",
    "# ==================================================\n",
    "# Rule 1: Drop COLUMNS that are more than 30% empty (Too much missing info)\n",
    "threshold_col = 30 # Percentage\n",
    "cols_to_drop = null_percent[null_percent > threshold_col].index.tolist()\n",
    "\n",
    "if cols_to_drop:\n",
    "    print(f\"\\n[ACTION] Dropping {len(cols_to_drop)} columns (> {threshold_col}% missing):\")\n",
    "    print(cols_to_drop)\n",
    "    df = df.drop(columns=cols_to_drop)\n",
    "else:\n",
    "    print(f\"\\n[ACTION] No columns exceeded the {threshold_col}% missing threshold.\")\n",
    "\n",
    "# Rule 2: Drop ROWS for whatever small missing data is left\n",
    "# (e.g. if one day is missing temp, we can't train on it)\n",
    "rows_before = len(df)\n",
    "df = df.dropna()\n",
    "rows_after = len(df)\n",
    "lost_rows = rows_before - rows_after\n",
    "\n",
    "print(f\"\\n[ACTION] Dropped {lost_rows} rows containing NaNs.\")\n",
    "\n",
    "# ==================================================\n",
    "# PART C: FINAL SAVE\n",
    "# ==================================================\n",
    "print(f\"\\nFinal Clean Shape: {df.shape}\")\n",
    "df.to_csv('Final_Cleaned_Dataset.csv', index=False)\n",
    "print(\"Saved as: 'Final_Cleaned_Dataset.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "418348bf-4cb8-4395-a29a-95b3950054c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ROW REDUCTION REPORT ---\n",
      "1. Original Data:       69,012 rows\n",
      "2. After Weather Merge: 69,012 rows (Difference: 0)\n",
      "3. After Cleaning Nulls:63,261 rows (Dropped: 5,751 rows)\n",
      "------------------------------\n",
      "Total Rows Lost: 5,751\n",
      "Data Retention:  91.67%\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Load the Three Datasets\n",
    "try:\n",
    "    df_orig = pd.read_csv('India_Elec_data_(Jan2020-Mar2025).csv')\n",
    "    df_model = pd.read_csv('Final_Model_Data.csv')       # Before cleaning nulls\n",
    "    df_clean = pd.read_csv('Final_Cleaned_Dataset.csv')  # After cleaning nulls\n",
    "\n",
    "    # 2. Get Row Counts\n",
    "    rows_orig = len(df_orig)\n",
    "    rows_model = len(df_model)\n",
    "    rows_clean = len(df_clean)\n",
    "\n",
    "    # 3. Print the Reduction Report\n",
    "    print(\"--- ROW REDUCTION REPORT ---\")\n",
    "    print(f\"1. Original Data:       {rows_orig:,} rows\")\n",
    "    print(f\"2. After Weather Merge: {rows_model:,} rows (Difference: {rows_model - rows_orig:,})\")\n",
    "    print(f\"3. After Cleaning Nulls:{rows_clean:,} rows (Dropped: {rows_model - rows_clean:,} rows)\")\n",
    "\n",
    "    # 4. Calculate Percentage Loss\n",
    "    total_loss = rows_orig - rows_clean\n",
    "    loss_pct = (total_loss / rows_orig) * 100\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Total Rows Lost: {total_loss:,}\")\n",
    "    print(f\"Data Retention:  {100 - loss_pct:.2f}%\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: Could not find one of the files. {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
